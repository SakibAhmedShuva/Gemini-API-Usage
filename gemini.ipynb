{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "api_key = \"AIzsfghjkjhrtgrsfgwerfvsdgmbXAZcU\" # Replace with your real key"
      ],
      "metadata": {
        "id": "JEi28Tjq49MF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "# --- IMPORTANT ---\n",
        "# 1. Replace \"YOUR_API_KEY\" with your actual API key.\n",
        "# 2. DO NOT share your real API key publicly like in your original example.\n",
        "#    It's best practice to use environment variables or a secret management system.\n",
        "# Example using an environment variable (recommended):\n",
        "# api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
        "# if not api_key:\n",
        "#     raise ValueError(\"Please set the GEMINI_API_KEY environment variable.\")\n",
        "# Or, for testing only (less secure):\n",
        "\n",
        "try:\n",
        "    # Configure the client with your API key\n",
        "    genai.configure(api_key=api_key) # Alternative way to set the key globally\n",
        "\n",
        "    print(\"Available models:\")\n",
        "    print(\"-\" * 20)\n",
        "\n",
        "    # Iterate through the list of models\n",
        "    for m in genai.list_models():\n",
        "        # Check if the model supports the 'generateContent' method\n",
        "        if 'generateContent' in m.supported_generation_methods:\n",
        "            print(f\"Model Name: {m.name}\")\n",
        "            # You can print other attributes too, like:\n",
        "            # print(f\"  Display Name: {m.display_name}\")\n",
        "            # print(f\"  Description: {m.description}\")\n",
        "            # print(f\"  Supported Methods: {m.supported_generation_methods}\")\n",
        "            print(\"-\" * 20)\n",
        "\n",
        "    print(\"\\nChoose one of the models listed above that supports 'generateContent' for your code.\")\n",
        "\n",
        "    # --- Example of using a valid model (replace with one from the list) ---\n",
        "    # Let's assume 'gemini-1.5-flash-latest' is available and supports generateContent\n",
        "    print(\"\\nAttempting to generate content with a potentially valid model...\")\n",
        "    try:\n",
        "        # Use a model name obtained from the list above\n",
        "        valid_model_name = \"gemini-1.5-flash-latest\" # Or another valid model like gemini-1.5-pro-latest\n",
        "\n",
        "        # Use the generate_content function directly from the genai module\n",
        "        # Or create a GenerativeModel instance first\n",
        "        model_instance = genai.GenerativeModel(valid_model_name)\n",
        "        response = model_instance.generate_content(\"Explain how AI works in a few words\")\n",
        "\n",
        "        # Or using the top-level function (less common for specific models now)\n",
        "        # response = genai.generate_content(\n",
        "        #     model=f\"models/{valid_model_name}\",  # Note: sometimes needs models/ prefix\n",
        "        #     contents=\"Explain how AI works in a few words\"\n",
        "        # )\n",
        "        print(\"\\nResponse:\")\n",
        "        print(response.text)\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError generating content even with a listed model: {e}\")\n",
        "        print(\"Please double-check the model name and ensure your API key is valid and has permissions.\")\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    print(\"Please ensure your API key is correct and valid.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zg5JSfvsr7BP",
        "outputId": "43dd112d-915b-4ef7-dd30-38f195c9c5de"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available models:\n",
            "--------------------\n",
            "Model Name: models/gemini-1.0-pro-vision-latest\n",
            "--------------------\n",
            "Model Name: models/gemini-pro-vision\n",
            "--------------------\n",
            "Model Name: models/gemini-1.5-pro-latest\n",
            "--------------------\n",
            "Model Name: models/gemini-1.5-pro-001\n",
            "--------------------\n",
            "Model Name: models/gemini-1.5-pro-002\n",
            "--------------------\n",
            "Model Name: models/gemini-1.5-pro\n",
            "--------------------\n",
            "Model Name: models/gemini-1.5-flash-latest\n",
            "--------------------\n",
            "Model Name: models/gemini-1.5-flash-001\n",
            "--------------------\n",
            "Model Name: models/gemini-1.5-flash-001-tuning\n",
            "--------------------\n",
            "Model Name: models/gemini-1.5-flash\n",
            "--------------------\n",
            "Model Name: models/gemini-1.5-flash-002\n",
            "--------------------\n",
            "Model Name: models/gemini-1.5-flash-8b\n",
            "--------------------\n",
            "Model Name: models/gemini-1.5-flash-8b-001\n",
            "--------------------\n",
            "Model Name: models/gemini-1.5-flash-8b-latest\n",
            "--------------------\n",
            "Model Name: models/gemini-1.5-flash-8b-exp-0827\n",
            "--------------------\n",
            "Model Name: models/gemini-1.5-flash-8b-exp-0924\n",
            "--------------------\n",
            "Model Name: models/gemini-2.5-pro-exp-03-25\n",
            "--------------------\n",
            "Model Name: models/gemini-2.5-pro-preview-03-25\n",
            "--------------------\n",
            "Model Name: models/gemini-2.5-flash-preview-04-17\n",
            "--------------------\n",
            "Model Name: models/gemini-2.0-flash-exp\n",
            "--------------------\n",
            "Model Name: models/gemini-2.0-flash\n",
            "--------------------\n",
            "Model Name: models/gemini-2.0-flash-001\n",
            "--------------------\n",
            "Model Name: models/gemini-2.0-flash-exp-image-generation\n",
            "--------------------\n",
            "Model Name: models/gemini-2.0-flash-lite-001\n",
            "--------------------\n",
            "Model Name: models/gemini-2.0-flash-lite\n",
            "--------------------\n",
            "Model Name: models/gemini-2.0-flash-lite-preview-02-05\n",
            "--------------------\n",
            "Model Name: models/gemini-2.0-flash-lite-preview\n",
            "--------------------\n",
            "Model Name: models/gemini-2.0-pro-exp\n",
            "--------------------\n",
            "Model Name: models/gemini-2.0-pro-exp-02-05\n",
            "--------------------\n",
            "Model Name: models/gemini-exp-1206\n",
            "--------------------\n",
            "Model Name: models/gemini-2.0-flash-thinking-exp-01-21\n",
            "--------------------\n",
            "Model Name: models/gemini-2.0-flash-thinking-exp\n",
            "--------------------\n",
            "Model Name: models/gemini-2.0-flash-thinking-exp-1219\n",
            "--------------------\n",
            "Model Name: models/learnlm-1.5-pro-experimental\n",
            "--------------------\n",
            "Model Name: models/learnlm-2.0-flash-experimental\n",
            "--------------------\n",
            "Model Name: models/gemma-3-1b-it\n",
            "--------------------\n",
            "Model Name: models/gemma-3-4b-it\n",
            "--------------------\n",
            "Model Name: models/gemma-3-12b-it\n",
            "--------------------\n",
            "Model Name: models/gemma-3-27b-it\n",
            "--------------------\n",
            "\n",
            "Choose one of the models listed above that supports 'generateContent' for your code.\n",
            "\n",
            "Attempting to generate content with a potentially valid model...\n",
            "\n",
            "Response:\n",
            "Learning patterns from data to make predictions.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client(api_key=api_key)\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-pro-exp-03-25\", contents=\"Explain how AI works in a few words\"\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "q2l9uCsds_qi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a55eed6-25f8-420e-a705-250fe791a7bb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here are a few ways:\n",
            "\n",
            "1.  **Computers learning from data to perform tasks.**\n",
            "2.  **Software mimicking human intelligence.**\n",
            "3.  **Machines finding patterns to make predictions or decisions.**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c5Qn9Qfm5Jhw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}